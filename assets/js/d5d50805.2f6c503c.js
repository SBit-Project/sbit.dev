"use strict";(self.webpackChunksbit_website=self.webpackChunksbit_website||[]).push([[7603],{6438:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"ddad","metadata":{"permalink":"/sbit.dev/blog/ddad","source":"@site/blog/2022-DDAD.md","title":"DDAO-Data-Management","description":"Data Management refers to the process of collecting, organizing, storing, processing, transmitting and retrieving different types of data. It is an important application area of the computer science. One of its goals is to efficiently store and manage complex, large amounts of data using computers, so that people can easily get access to the data. Another goal is to extract and derive valuable information from the data, and then use the information as a guidance for action and decision making.","date":"2022-04-27T15:25:34.000Z","formattedDate":"April 27, 2022","tags":[],"readingTime":8.865,"truncated":false,"authors":[{"name":"SBit Dev Team"}],"frontMatter":{"slug":"ddad","title":"DDAO-Data-Management","author":"SBit Dev Team"},"nextItem":{"title":"Sbit Exchange Usage Guide and Info","permalink":"/sbit.dev/blog/exchange"}},"content":"Data Management refers to the process of collecting, organizing, storing, processing, transmitting and retrieving different types of data. It is an important application area of the computer science. One of its goals is to efficiently store and manage complex, large amounts of data using computers, so that people can easily get access to the data. Another goal is to extract and derive valuable information from the data, and then use the information as a guidance for action and decision making.\\n\\nAt present, enterprises mainly use centralized databases and file systems for data management. Large Internet companies develop their own systems, such as GFS (Google File System), SQL Server, etc., and deploy local services. Small and medium-sized companies connect to cloud services such as AWS, Aliyun, and delegate data management tasks to these third parties. Local and cloud data services have their own application scenarios and they maintain the basic data of many companies.\\n\\nCentralized storage is currently the main solution to data management, but there are serious storage problems in centralized databases and file systems around the world. Enterprises often store all their data and files in centralized databases and file systems. But centralized storage solutions often attract attacks from hackers, or they may be ruined by an accident. Enterprises sometimes have to face the loss of all their data resources and never get them back. Some business highly relys on data and such kind of loss may lead to huge risks. Although cloud service providers would promise to do data backup, but it has not solved the fundamental problem.\\n\\nDecentralization technologies, such as blockchain and IPFS, provide a new type of solutions to data management. By using encryption and consensus, data privacy and security are guaranteed. Since data are stored in a lot of nodes, there is no need to worry about data loss caused by failure of \\bone single node, which improves security and reliability. Encryption and segmentation technologies control the read access and guarantee data privacy. At the same time, in order to ensure scalability, cluster technology is used. A cluster is a large group of nodes that store and manage data together, and it allows new nodes to join or expanding more clusters.\\n\\nHowever, at present, with the increasing number of decentralized systems, developers have to face high costs in selection, learning, development, deployment, and maintenance of these systems. Therefore we proposed the DDAO (Decentralized Data Access Object). Our goal is to develop a common library to access various decentralized systems with uniform interfaces, so as to perform CRUD (Create, Read, Update, Delete) operations. Through this library, developers can quickly read and write data in various decentralized systems and build their own applications without having to care about the underlying technology.\\n\\n## Related Work\\nWith the development of blockchain technology and digital currency market, decentralized data storage and management technologies receive attentions from research fields and investment markets.\\n\\n## Decentralized File System\\nAs a decentralized system, blockchain backs up data at every node, so it is not suitable for storing large-size files, such as pictures, videos and audios. In current blockchain applications, such kind of files are still stored in servers held by developers. This way leads to the centralization of these applications, which violates the essential meaning of blockchain.\\n\\nDecentralized file systems mainly include IPFS (InterPlanetary File System) [1], Swarm [2], Storj [3], and so on. Their basic method is to split the uploaded file into small pieces and then store them into nodes. When downloading the file, you can use the hash value of the file as an address to make a request to a node, and then you will get all the data pieces from the node and combine them into the whole file. In this way, one file can be separately stored in many nodes in a network, which achieves decentralization.\\n\\nOne problem with these technologies is how to keep more nodes online to provide download services. Hence, some projects propose to add node incentive mechanisms to the decentralized file system so that online nodes can obtain revenues. In this way, the decentralized file system becomes a cloud storage service, in which users need to purchase the service during uploading and downloading processes so as to reward the nodes that provide the storage service. Several typical projects include Filecoin [4], Wolk [5], Fluence [6], and Sia [7].\\n\\n## Decentralized Database\\nThe decentralized file system enables decentralized storage of data, but after the data are uploaded, they cannot be further modified or retrieved, which limits its application in data management. Traditional centralized data management services usually use database systems such as MySQL or Redis to execute CRUD operations of data. Therefore, similar database services are required in the decentralized area.\\n\\nThere are several projects having research on decentralized databases, including BigchainDB [8], Bluzelle [9], Ties.DB [10] and so on. Their basic idea is to upload database write requests to the blockchain through transactions, and then use database engines such as MongoDB to perform data indexing and process read requests. Using blockchain to build decentralized databases, effectively utilizes the mature decentralized architecture of blockchain systems, and has great advantages in stability and security.\\n\\nThese projects are currently in their initial stages, and before their implementations mature, using smart contracts as a database service is also a viable alternative. Some projects are based on Ethereum + IPFS to develop their applications, using smart contracts written by Solidity for data management. Solidity supports data structures such as List, Map, Struct, etc., which are sufficient for common data management scenarios. These items are fully enumerated in [11].\\n\\n## System Description\\nDecentralized systems have a variety of implementations, leading to high learning costs for developers. This article will design a common library for connecting upper-layer DApp applications to lower-layer decentralized systems, enabling CRUD operations for multiple decentralized systems. Developers can quickly build their own data management applications through this library without having knowledge about the underlying technology. At the same time, based on this library, a cloud service can be built to provide online CRUD interfaces of multiple decentralized systems, eliminating the cost of deploying and maintaining decentralized systems for developers.\\n\\nThe system can be separated into three layers, namely DDMI (Decentralized Data Management Infrastructure), DDAO and DApp (Decentralized Application), which will be introduced as follows.\\n\\n## DDMI\\nThe DDMI layer contains a variety of decentralized systems, including blockchains, decentralized databases, decentralized file systems, and more. These decentralized systems can be launched locally by the developer or deployed on a remote server, and then connected through a descriptor with uniform format. For example, the format of *name://user:password@ip:port*, that is, connecting to a local Sbit node with port 22302 by *sbit://admin:123456@127.0.0.1:22302*, or connecting to an IPFS node in LAN with 8080 port by *ipfs://myname:mypasswd@192.168.1.2:8080*.\\n\\n## DDAO\\nThe DDAO layer is the core module proposed in this paper. Its main functions include (1) establishing connections to various decentralized systems, (2) abstracting to get compatible CRUD interfaces. For different types of decentralized systems, abstract interfaces are different:\\n\\n1. For blockchain systems, interfaces contain sending transactions, querying transactions, creating contracts, reading and writing contracts.\\n2. For decentralized database systems, database interfaces such as create, find, insert, and update are included.\\n3. For decentralized file systems, main interfaces such as file upload, download, and encryption are included.\\n\\nThe design here needs to take into account the compatibility of different systems, so only some common functions are abstracted. At the same time, the interface used to send original commands is offered, so that developers can request some unique interfaces of each system.\\n\\n## DApp\\nThe DApp can be JavaScript scripts running on browser or programs running on server. They may also be stored in the decentralized file system and later obtained through a specific address as an entry. The DApp initiates the DDAO instance, connects local or cloud decentralized systems, and performs CRUD operations on these systems, so as to realize data management applications.\\n\\nMultiple DDAO instances can be initiated within one DApp, in order to connect to multiple different decentralized systems. This allows data interaction with multiple decentralized systems in one application, enabling more features compared with traditional smart contract-based DApps. For example, cross-chain data transmission among multiple blockchains, or data visualization based on blockchain and file system.\\n\\n## Application Scenario\\nA large number of application scenarios is the best way to describe the value of DDAO. Based on DDAO, many decentralized applications will become easy to develop and implement.\\n\\n## Decentralized Content Sharing\\nDDAO can be used to build a blog, photo, music, video sharing platform. By using DDAO\'s write interfaces, users can publish texts, images, videos and other content to a decentralized file system such as IPFS, and then store their meta data (such as content address, release time, user ID, etc.) into a smart contract or a database. The DDAO read interfaces are used to filter, sort, and display the content. The advantage of such system is that the contents published by users is decentralized and cannot be tampered with.\\n\\n## Decentralized Trading Platform\\nBased on DDAO, you can build a trading platform like Taobao and Amazon. When a merchant uses DDAO write interfaces to upload its product information, the text and image are stored in a decentralized file system, and the meta data (such as price, quantity, classification, keywords, etc.) are stored in a smart contract or a database. When a customer browses the platform, DDAO read interfaces are used to search and filter products. Finally, the customer uses DDAO to connect to the blockchain to create orders, pay orders, and complete orders. The advantage of this platform is that the product information and transaction process are transparent and the payment process is convenient.\\n\\n## Decentralized Cloud Storage Service\\nStorage service providers register their information into a blockchain or a database via DDAO. When a user uploads a file, he needs to use blockchain tokens to purchase the service, and then uploads the file to a decentralized file system through DDAO, while the file information and address are stored in a smart contract or a database. When downloading, users browse the file information and address by using DDAO, and then download the file from the file system. The tokens consumed by the user are used to reward storage service providers, forming a complete economic ecology.\\n\\n# Summary\\nDecentralized data management has broad application prospects. Although, at present, decentralized databases and file systems are still under development, and immature infrastructure limits its application, it is conceivable that these systems will be implemented one after another in the near future. DDAO will also be widely used just like the DAO in current centralized systems."},{"id":"exchange","metadata":{"permalink":"/sbit.dev/blog/exchange","source":"@site/blog/2022-Exchange.md","title":"Sbit Exchange Usage Guide and Info","description":"Setup","date":"2022-04-27T15:25:34.000Z","formattedDate":"April 27, 2022","tags":[],"readingTime":5.715,"truncated":false,"authors":[{"name":"SBit Dev Team"}],"frontMatter":{"slug":"exchange","title":"Sbit Exchange Usage Guide and Info","author":"SBit Dev Team"},"prevItem":{"title":"DDAO-Data-Management","permalink":"/sbit.dev/blog/ddad"},"nextItem":{"title":"PoS in SBit","permalink":"/sbit.dev/blog/pos"}},"content":"## Setup\\n\\nYou can download a pre-built version of Sbit from our Github Release page\\n\\nSimply extract the .tar.gz linux-64bit archive. In the \\"bin\\" directory will be the two programs of interest, sbitd and sbit-cli\\n\\nIf you choose to compile it yourself instead, follow these steps on Ubuntu:\\n\\nInstall packages if needed:\\n\\n\\n``` bash\\nsudo apt-get install build-essential libtool autotools-dev automake pkg-config libssl-dev libevent-dev bsdmainutils git cmake libboost-all-dev\\n\\nsudo apt-get install software-properties-common\\n\\nsudo add-apt-repository ppa:bitcoin/bitcoin\\n\\nsudo apt-get update\\n\\nsudo apt-get install libdb4.8-dev libdb4.8++-dev\\n```\\n\\n\\n\\n``` bash\\ngit clone https://github.com/SBit-Project/sbit --recursive\\n./autogen.sh\\n./configure --with-gui=no --enable-hardening\\nmake -j3\\n```\\n\\nAfterwards, in the \\"src\\" directory, there will be two programs of interest, `sbitd` and `sbit-cli`\\n\\n## Startup\\n\\nIn order to startup sbitd, use the following:\\n\\n\\n``` bash\\n./sbitd -daemon -staking=0\\n```\\n\\nAdditional options can be specified in `~/.sbit/sbit.conf`, you can add `-staking=0` in the sbit.conf file\\n\\nAfterwards, you can check the status of the Sbit node:\\n\\n\\n``` bash\\n./sbit-cli getinfo\\n```\\n\\n\\nIt will show a block count. when the block count matches the latest block on our block explorer: [https://explorer.sbit.org](https://explorer.sbit.org) then that means that the node is synchronized. If it shows 0 blocks and 0 connections for more than a few minutes, contact Sbit staff for help. Syncing the blockchain will take around 10-30 minutes depending on connection speed\\n\\n\\nIn order to shut down the node, simply use:\\n\\n``` bash\\n./sbit-cli stop\\n```\\n\\n:::caution\\n`-staking=false` disables automatic staking in the wallet. This is **HIGHLY RECOMMENDED** for exchanges. Staking can make an unpredictable amount of coins unaccessible for 500 blocks (~20 hours) and so it is recommended that exchanges do not participate in staking.\\n:::\\n\\n## Wallet Backup\\n\\nMake sure to always back up your wallet! The location of the wallet file on Linux is `~/.sbit/wallet.dat`. Make sure to shut down the node before making a backup to avoid data corruption.\\n\\nThe wallet can also be encrypted on-disk:\\n\\n\\n``` bash\\n./sbit-cli encryptwallet \\"your strong password\\"\\n```\\n\\nThe Sbit node will automatically stop itself in order to encrypt the wallet. You will need to execute `./sbitd -daemon -staking=false` again afterwards to start the node again\\n\\n:::danger Warning\\n**IMPORTANT:** after encrypting the wallet **YOU MUST** make a new backup of the wallet.dat file. Failing to do so can result in **LOSS OF COINS**. If the password to the encrypted wallet is lost, there is **NO WAY TO RECOVER THE COINS**. Make sure to take backups of both wallet.dat, as well as the password used for encryption!\\n:::\\n\\nIn order to unlock the wallet:\\n\\n\\n``` bash\\n./sbit-cli walletpassphrase \\"your strong password\\" XXX\\n```\\n\\n\\nXXX is how many seconds to keep the wallet unlocked for. So, specifying that as \\"1000\\" would mean keep the wallet unlocked for 1000 seconds.\\n\\nFor an exchange it is probably best to not use wallet encryption on the hot wallet. In the above example, after 1000 seconds have passed, it is necessary to unlock the wallet again. This may cause some problems depending on your exact exchange systems\\n\\n:::note\\n**NOTE:** Unlocking the wallet is only required to send coins. If you only need to receive coins and track transactions, this can be done with an encrypted and locked wallet\\n:::\\n\\n## Receiving coins\\n\\nIn order to generate a new address:\\n\\n\\n``` bash\\n./sbit-cli getnewaddress \\"\\"\\n```\\n\\nThis will generate a unique address every time it is executed. Note Sbit addresses start with S for standard pubkeyhash addresses, and start with M for multi-sig addresses\\n\\nTo validate an address is valid:\\n\\n\\n``` bash\\n./sbit-cli validateaddress \\"address here\\"\\n```\\n\\nIn order to see the coins received by a particular address (note the address must be owned by this wallet. This does not allow checking addresses not owned by this wallet):\\n\\n\\n```  bash\\n./sbit-cli getreceivedbyaddress \\"address here\\" MINCONF\\n```\\n\\nIn this case, `MINCONF` is how many confirmations the transaction must have had on the blockchain before it will be included in this number.\\n\\nMinimum confirmations recommended by Sbit:\\n\\n- 20 confirmations for very large amounts and for any amount during the first month of the mainnet launch\\n- 10 confirmations for small and medium amounts after 1 month when the network is proven stable\\n\\nTo get all transactions (including unconfirmed!) currently tracked by the wallet use this function:\\n\\n``` bash\\n./sbit-cli listtransactions \\"*\\" COUNT SKIP\\n```\\n\\nCOUNT and SKIP can be used for paging through transactions. Using a very large count value may cause the node to perform the request slowly, and so it is recommended to never use a COUNT that is more than 100. SKIP is used to skip the first number of results. It is not recommended to rely only on this for the accounting of an exchange. It is possible that while you are iterating to discover the full transaction list, that someone sends a transaction to the wallet that will be missed. Also, this method includes **UNCONFIRMED** transactions and must be used with caution.\\n\\n:::danger Warning\\n**WARNING**: Bitcoind and thus sbitd has some account functionality so that different addresses can use different accounts. **DO NOT RELY ON THIS**. This feature is deprecated and has many security problems, and will be removed in the next release.\\n:::\\n\\n## Sending Coins\\n\\nIt is not easily possible to dictate what address coins should be sent from. If your exchange system relies on this, you should make a workaround in your system so that this is not necessary.\\n\\nIn order to send coins:\\n\\n\\n``` bash\\n./sbit-cli sendtoaddress \\"address to send to\\" AMOUNT \\"comment about tx\\" \\"comment about address\\" SUBTRACTFEE\\n```\\n\\nThe \\"comment\\" arguments can be left blank if unneeded. These comments are saved within your wallet file and are used by some exchanges to track internal withdraw and user IDs.\\n\\nThe SUBTRACTFEE option can be either \\"true\\" or \\"false\\". When this option is true, it subtracts the fee from the amount sent. So, if you do\\n\\n\\n``` bash\\n./sbit-cli sendtoaddress \\"address\\" 10 \\"\\" \\"\\" true\\n```\\n\\nAnd the network fee is 0.1 Sbit, then the actual amount that the user will receive will be 9.9 Sbit. If SUBTRACTFEE is instead set to false, then they will receive 10, but your wallet will have paid 0.1 Sbit for the network fee.\\n\\n:::caution\\n**NOTE:** Exchange users should not be capable of sending coins directly to a smart contract address (one starting with 0x). These addresses will be rejected by sendtoaddress and proper usage requires significantly more caution to properly use.\\n:::\\n\\n## Parameters\\n:::tip\\nRecommended tx fee: 400000 sat or 0.004 Sbit per kilobyte of tx data (2kb is reasonable transaction size expectation, but it can sometimes be more)\\n:::\\n\\n:::tip\\nRecommended confirmations: 20 for the first month, 10 afterwards\\n:::\\n\\n:::tip\\nRecommended minimum withdraw amount: 0.01 Sbit\\n:::\\n\\n:::tip\\nP2P Network Port: 22001 (port forwarding is not required or recommended, but the wallet must be able to access other external nodes through this port to download the blockchain)\\n:::"},{"id":"pos","metadata":{"permalink":"/sbit.dev/blog/pos","source":"@site/blog/2022-PoS.md","title":"PoS in SBit","description":"In every cryptocurrency there must be some consensus mechanism which keeps the entire distributed network in sync. When Bitcoin first came out, it introduced the Proof of Work (PoW) system. PoW is done by cryptographically hashing a piece of data (the block header) over and over. Because of how one-way hashing works. One tiny change in the data can cause an extremely different hash to come of it. Participants in the network determine if the PoW is valid complete by judging if the final hash meets a certain condition, called difficulty. The difficulty is an ever changing \\"target\\" which the hash must meet or exceed. Whenever the network is creating more blocks than scheduled, this target is changed automatically by the network so that the target becomes more and more difficult to meet. And thus, requires more and more computing power to find a hash that matches the target within the target time of 10 minutes.","date":"2022-04-27T15:25:34.000Z","formattedDate":"April 27, 2022","tags":[],"readingTime":14.845,"truncated":false,"authors":[{"name":"SBit Dev Team"}],"frontMatter":{"slug":"pos","title":"PoS in SBit","author":"SBit Dev Team"},"prevItem":{"title":"Sbit Exchange Usage Guide and Info","permalink":"/sbit.dev/blog/exchange"}},"content":"In every cryptocurrency there must be some consensus mechanism which keeps the entire distributed network in sync. When Bitcoin first came out, it introduced the Proof of Work (PoW) system. PoW is done by cryptographically hashing a piece of data (the block header) over and over. Because of how one-way hashing works. One tiny change in the data can cause an extremely different hash to come of it. Participants in the network determine if the PoW is valid complete by judging if the final hash meets a certain condition, called difficulty. The difficulty is an ever changing \\"target\\" which the hash must meet or exceed. Whenever the network is creating more blocks than scheduled, this target is changed automatically by the network so that the target becomes more and more difficult to meet. And thus, requires more and more computing power to find a hash that matches the target within the target time of 10 minutes.\\n\\nDefinitions\\nSome basic definitions might be unfamiliar to some people not familiar with the blockchain code, these are:\\n\\nUTXO - Unspent Transaction Output\\nvin - In a transaction a \'vin\' is a UTXO that is being spent as an \\"input\\"\\nvout - In a transaction, a \'vout\' is the new UTXO that is being created as an \\"output\\". The \'vouts\' is effectively all of the coins sent after the transaction is complete\\nhashing - The process of creating a hash. This takes an arbritrary amount of data as input, and outputs a fixed size \\"digest\\" which is impossible to reverse. Additionally, if you change anything about the input data, it drastically changes the output digest.\\nhash - The result of a hashing algorithm.\\nscript - The computer program that determines how a vout/UTXO is spent.\\npay-to-pubkeyhash script - The most common script used to send money in Bitcoin and other cryptocurrencies. In order to send money, all you need to know is the hash of their public key (commonly represented as a base58 address), and in order to spend the received money all that is needed is a signature from the public key, and the public key itself.\\npay-to-pubkey script - A very simple script which has very similar functionality to pubkeyhash scripts. However, instead of sending money to the hash of a public key, the money is sent to the public key itself. All that is needed for spending is a cryptographic signature proving ownership of the public key.\\nprevout - The vout which is spent (as a vin) in a transaction\\nOP_RETURN script - OP_RETURN is an operation used in script which effectively makes an output provably unspendable. It is commonly used to hold small amounts of data on the blockchain without polluting the UTXO set.\\nProof of Work and Blockchain Consensus Systems\\nProof of Work is a proven consensus mechanism that has made Bitcoin secure and trustworthy for 8 years now. However, it is not without it\'s fair share of problems. PoW\'s major drawbacks are:\\n\\nPoW wastes a lot of electricity, harming the environment.\\nPoW benefits greatly from economies of scale, so it tends to benefit big players the most, rather than small participants in the network.\\nPoW provides no incentive to use or keep the tokens.\\nPoW has some centralization risks, because it tends to encourage miners to participate in the biggest mining pool (a group of miners who share the block reward), thus the biggest mining pool operator holds a lot of control over the network.\\nProof of Stake was invented to solve many of these problems by allowing participants to create and mine new blocks (and thus also get a block reward), simply by holding onto coins in their wallet and allowing their wallet to do automatic \\"staking\\". Proof Of Stake was originally invented by Sunny King and implemented in Peercoin. It has since been improved and adapted by many other people. This includes \\"Proof of Stake Version 2\\" by Pavel Vasin, \\"Proof of Stake Velocity\\" by Larry Ren, and most recently CASPER by Vlad Zamfir, as well as countless other experiments and lesser known projects.\\n\\nFor SBit we have decided to build upon \\"Proof of Stake Version 3\\", an improvement over version 2 that was also made by Pavel Vasin and implemented in the Blackcoin project. This version of PoS as implemented in Blackcoin is what we will be describing here. Some minor details of it has been modified in SBit, but the core consensus model is identical.\\n\\nFor many community members and developers alike, proof of stake is a difficult topic, because there has been very little written on how it manages to accomplish keeping the network safe using only proof of ownership of tokens on the network. This blog post will go into fine detail about Proof of Stake Version 3 and how it\'s blocks are created, validated, and ultimately how a pure Proof of Stake blockchain is possible to secure. This will assume some technical knowledge, but I will try to explain things so that most of the knowledge can be gathered from context. You should at least be familiar with the concept of the UTXO-based blockchain.\\n\\nBefore we talk about PoS, it helps to understand how the much simpler PoW consensus mechanism works. It\'s mining process can be described in just a few lines of pseudo-code:\\n\\nwhile(blockhash > difficulty) {\\n  block.nonce = block.nonce + 1\\n  blockhash = sha256(sha256(block))\\n}\\nA hash is a cryptographic algorithm which takes an arbritrary amount of input data, does a lot of processing of it, and outputs a fixed-size \\"digest\\" of that data. It is impossible to figure out the input data with just the digest. So, PoW tends to function like a lottery, where you find out if you won by creating the hash and checking it against the target, and you create another ticket by changing some piece of data in the block. In Bitcoin\'s case, nonce is used for this, as well as some other fields (usually called \\"extraNonce\\"). Once a blockhash is found which is less than the difficulty target, the block is valid, and can be broadcast to the rest of the distributed network. Miners will then see it and start building the next block on top of this block.\\n\\nProof of Stake\'s Protocol Structures and Rules\\nNow enter Proof of Stake. We have these goals for PoS:\\n\\nImpossible to counterfeit a block\\nBig players do not get disproportionally bigger rewards\\nMore computing power is not useful for creating blocks\\nNo one member of the network can control the entire blockchain\\nThe core concept of PoS is very similar to PoW, a lottery. However, the big difference is that it is not possible to \\"get more tickets\\" to the lottery by simply changing some data in the block. Instead of the \\"block hash\\" being the lottery ticket to judge against a target, PoS invents the notion of a \\"kernel hash\\".\\n\\nThe kernel hash is composed of several pieces of data that are not readily modifiable in the current block. And so, because the miners do not have an easy way to modify the kernel hash, they can not simply iterate through a large amount of hashes like in PoW.\\n\\nProof of Stake blocks add many additional consensus rules in order to realize it\'s goals. First, unlike in PoW, the coinbase transaction (the first transaction in the block) must be empty and reward 0 tokens. Instead, to reward stakers, there is a special \\"stake transaction\\" which must be the 2nd transaction in the block. A stake transaction is defined as any transaction that:\\n\\nHas at least 1 valid vin\\nIt\'s first vout must be an empty script\\nIt\'s second vout must not be empty\\nFurthermore, staking transactions must abide by these rules to be valid in a block:\\n\\nThe second vout must be either a pubkey (not pubkeyhash!) script, or an OP_RETURN script that is unspendable (data-only) but stores data for a public key\\nThe timestamp in the transaction must be equal to the block timestamp\\nthe total output value of a stake transaction must be less than or equal to the total inputs plus the PoS block reward plus the block\'s total transaction fees. output <= (input + block_reward + tx_fees)\\nThe first spent vin\'s output must be confirmed by at least 500 blocks (in otherwords, the coins being spent must be at least 500 blocks old)\\nThough more vins can used and spent in a staking transaction, the first vin is the only one used for consensus parameters.\\nThese rules ensure that the stake transaction is easy to identify, and ensures that it gives enough info to the blockchain to validate the block. The empty vout method is not the only way staking transactions could have been identified, but this was the original design from Sunny King and has worked well enough.\\n\\nNow that we understand what a staking transaction is, and what rules they must abide by, the next piece is to cover the rules for PoS blocks:\\n\\nMust have exactly 1 staking transaction\\nThe staking transaction must be the second transaction in the block\\nThe coinbase transaction must have 0 output value and a single empty vout\\nThe block timestamp must have it\'s bottom 4 bits set to 0 (referred to as a \\"mask\\" in the source code). This effectively means the blocktime can only be represented in 16 second intervals, decreasing it\'s granularity\\nThe version of the block must be 7\\nA block\'s \\"kernel hash\\" must meet the weighted difficulty for PoS\\nThe block hash must be signed by the public key in the staking transaction\'s second vout. The signature data is placed in the block (but is not included in the formal block hash)\\nThe signature stored in the block must be \\"LowS\\", which means consisting only of a single piece of data and must be as compressed as possible (no extra leading 0s in the data, or other opcodes)\\nMost other rules for standard PoW blocks apply (valid merkle hash, valid transactions, timestamp is within time drift allowance, etc)\\nThere are a lot of details here that we\'ll cover in a bit. The most important part that really makes PoS effective lies in the \\"kernel hash\\". The kernel hash is used similar to PoW (if hash meets difficulty, then block is valid). However, the kernel hash is not directly modifiable in the context of the current block. We will first cover exactly what goes into these structures and mechanisms, and later explain why this design is exactly this way, and what unexpected consequences can come from minor changes to it.\\n\\nThe Proof of Stake Kernel Hash\\nThe kernel hash specifically consists of the following exact pieces of data (in order):\\n\\nPrevious block\'s \\"stake modifier\\" (more detail on this later)\\nTimestamp from \\"prevout\\" transaction (the transaction output that is spent by the first vin of the staking transaction)\\nThe hash of the prevout transaction\\nThe output number of the prevout (ie, which output of the transaction is spent by the staking transaction)\\nCurrent block time, with the bottom 4 bits set to 0 to reduce granularity. This is the only thing that changes during staking process\\nThe stake modifier of a block is a hash of exactly:\\n\\nThe hash of the prevout transaction in PoS blocks, OR the block hash in PoW blocks.\\nThe previous block\'s stake modifier (the genesis block\'s stake modifier is 0)\\nThe only way to change the current kernel hash (in order to mine a block), is thus to either change your \\"prevout\\", or to change the current block time.\\n\\nA single wallet typically contains many UTXOs. The balance of the wallet is basically the total amount of all the UTXOs that can be spent by the wallet. This is of course the same in a PoS wallet. This is important though, because any output can be used for staking. One of these outputs are what can become the \\"prevout\\" in a staking transaction to form a valid PoS block.\\n\\nFinally, there is one more aspect that is changed in the mining process of a PoS block. The difficulty is weighted against the number of coins in the staking transaction. The PoS difficulty ends up being twice as easy to achieve when staking 2 coins, compared to staking just 1 coin. If this were not the case, then it would encourage creating many tiny UTXOs for staking, which would bloat the size of the blockchain and ultimately cause the entire network to require more resources to maintain, as well as potentially compromise the blockchain\'s overall security.\\n\\nSo, if we were to show some pseudo-code for finding a valid kernel hash now, it would look like:\\n\\n```cpp\\nwhile(true){\\n    foreach(utxo in wallet){\\n        blockTime = currentTime - currentTime % 16\\n        posDifficulty = difficulty * utxo.value\\n        hash = hash(previousStakeModifier << utxo.time << utxo.hash << utxo.n << blockTime)\\n        if(hash < posDifficulty){\\n            done\\n        }\\n    } \\n    wait 16s -- wait 16 seconds, until the block time can be changed\\n}\\n```\\n\\nThis code isn\'t so easy to understand as our PoW example, so I\'ll attempt to explain it in plain english:\\n\\nDo the following over and over for infinity: \\nCalculate the blockTime to be the current time minus itself modulus 16 (modulus is like dividing by 16, but then only instead of taking the result, taking the remainder)\\nCalculate the posDifficulty as the network difficulty, multiplied by the number of coins held by the UTXO. \\nCycle through each UTXO in the wallet. With each UTXO, calculate a SHA256 hash using the previous block\'s stake modifier, as well as some data from the the UTXO, and finally the blockTime. Compare this hash to the posDifficulty. If the hash is less than the posDifficulty, then the kernel hash is valid and you can create a new block. \\nAfter going through all UTXOs, if no hash produced is less than the posDifficulty, then wait 16 seconds and do it all over again. \\nNow that we have found a valid kernel hash using one of the UTXOs we can spend, we can create a staking transaction. This staking transaction will have 1 vin, which spends the UTXO we found that has a valid kernel hash. It will have (at least) 2 vouts. The first vout will be empty, identifying to the blockchain that it is a staking transaction. The second vout will either contain an OP_RETURN data transaction that contains a single public key, or it will contain a pay-to-pubkey script. The latter is usually used for simplicity, but using a data transaction for this allows for some advanced use cases (such as a separate block signing machine) without needlessly cluttering the UTXO set.\\n\\nFinally, any transactions from the mempool are added to the block. The only thing left to do now is to create a signature, proving that we have approved the otherwise valid PoS block. The signature must use the public key that is encoded (either as pay-pubkey script, or as a data OP_RETURN script) in the second vout of the staking transaction. The actual data signed in the block hash. After the signature is applied, the block can be broadcast to the network. Nodes in the network will then validate the block and if it finds it valid and there is no better blockchain then it will accept it into it\'s own blockchain and broadcast the block to all the nodes it has connection to.\\n\\nNow we have a fully functional and secure PoSv3 blockchain. PoSv3 is what we determined to be most resistant to attack while maintaining a pure decentralized consensus system (ie, without master nodes or currators). To understand why we approached this conclusion however, we must understand it\'s history.\\n\\nPoSv3\'s History\\nProof of Stake has a fairly long history. I won\'t cover every detail, but cover broadly what was changed between each version to arrive at PoSv3 for historical purposes:\\n\\nPoSv1 - This version is implemented in Peercoin. It relied heavily on the notion of \\"coin age\\", or how long a UTXO has not been spent on the blockchain. It\'s implementation would basically make it so that the higher the coin age, the more the difficulty is reduced. This had the bad side-effect however of encouraging people to only open their wallet every month or longer for staking. Assuming the coins were all relatively old, they would almost instantaneously produce new staking blocks. This however makes double-spend attacks extremely easy to execute. Peercoin itself is not affected by this because it is a hybrid PoW and PoS blockchain, so the PoW blocks mitigated this effect.\\n\\nPoSv2 - This version removes coin age completely from consensus, as well as using a completely different stake modifier mechanism from v1. The number of changes are too numerous to list here. All of this was done to remove coin age from consensus and make it a safe consensus mechanism without requiring a PoW/PoS hybrid blockchain to mitigate various attacks.\\n\\nPoSv3 - PoSv3 is really more of an incremental improvement over PoSv2. In PoSv2 the stake modifier also included the previous block time. This was removed to prevent a \\"short-range\\" attack where it was possible to iteratively mine an alternative blockchain by iterating through previous block times. PoSv2 used block and transaction times to determine the age of a UTXO; this is not the same as coin age, but rather is the \\"minimum confirmations required\\" before a UTXO can be used for staking. This was changed to a much simpler mechanism where the age of a UTXO is determined by it\'s depth in the blockchain. This thus doesn\'t incentivize inaccurate timestamps to be used on the blockchain, and is also more immune to \\"timewarp\\" attacks. PoSv3 also added support for OP_RETURN coinstake transactions which allows for a vout to contain the public key for signing the block without requiring a full pay-to-pubkey script."}]}')}}]);